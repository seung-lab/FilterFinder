{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate effectiveness of FilterFinder on all experiments  \n",
    "Thomas Macrina  \n",
    "May 17, 2017  \n",
    "\n",
    "Inspecting meshsets for FilterFinder evaluation. \n",
    "\n",
    "Evaluating on gcloud with instance `alembic-davittest-across`  \n",
    "\n",
    "We had success with our first batch of meshsets (`standard_224`), so now we're analyzing results from all the experiments here:  \n",
    "`gs://image_assembly/experiments/davit_piritest/meshset_inspected/`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: could not import LinAlg.A_ldiv_B into DSS\n",
      "WARNING: Union(args...) is deprecated, use Union{args...} instead.\n",
      " in depwarn at deprecated.jl:73\n",
      " in call at deprecated.jl:50\n",
      " in anonymous at no file\n",
      " in include at ./boot.jl:261\n",
      " in include_from_node1 at ./loading.jl:320\n",
      " in include at ./boot.jl:261\n",
      " in include_from_node1 at ./loading.jl:320\n",
      " in include at ./boot.jl:261\n",
      " in include_from_node1 at ./loading.jl:320\n",
      " in require at ./loading.jl:259\n",
      " in include at ./boot.jl:261\n",
      " in include_from_node1 at ./loading.jl:320\n",
      " in require at ./loading.jl:259\n",
      " in include_string at loading.jl:282\n",
      " in execute_request at /home/ubuntu/.julia/v0.4/IJulia/src/execute_request.jl:164\n",
      " in eventloop at /home/ubuntu/.julia/v0.4/IJulia/src/IJulia.jl:138\n",
      " in anonymous at task.jl:447\n",
      "while loading /home/ubuntu/.julia/v0.4/MKLSparse/src/./DSS/dss_generator.jl, in expression starting on line 3\n",
      "WARNING: Union(args...) is deprecated, use Union{args...} instead.\n",
      " in depwarn at deprecated.jl:73\n",
      " in call at deprecated.jl:50\n",
      " in anonymous at no file\n",
      " in include at ./boot.jl:261\n",
      " in include_from_node1 at ./loading.jl:320\n",
      " in include at ./boot.jl:261\n",
      " in include_from_node1 at ./loading.jl:320\n",
      " in include at ./boot.jl:261\n",
      " in include_from_node1 at ./loading.jl:320\n",
      " in require at ./loading.jl:259\n",
      " in include at ./boot.jl:261\n",
      " in include_from_node1 at ./loading.jl:320\n",
      " in require at ./loading.jl:259\n",
      " in include_string at loading.jl:282\n",
      " in execute_request at /home/ubuntu/.julia/v0.4/IJulia/src/execute_request.jl:164\n",
      " in eventloop at /home/ubuntu/.julia/v0.4/IJulia/src/IJulia.jl:138\n",
      " in anonymous at task.jl:447\n",
      "while loading /home/ubuntu/.julia/v0.4/MKLSparse/src/./DSS/dss_generator.jl, in expression starting on line 3\n",
      "WARNING: using Datasource.get in module Main conflicts with an existing identifier.\n",
      "WARNING: requiring \"Alembic\" in module \"Main\" did not define a corresponding module.\n"
     ]
    }
   ],
   "source": [
    "using Alembic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,1002-1,1096_aligned.jls  \n",
    "1,2002-1,2096_aligned.jls  \n",
    "1,2-1,96_aligned.jls  \n",
    "1,3002-1,3096_aligned.jls\n",
    "\n",
    "0-thousands: original  \n",
    "1-thousands: net trained on adj  \n",
    "2-thousands: net trained on across  \n",
    "3-thousands: bandpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /home/ubuntu/davit/standard_224/1,3002-1,3096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/standard_224/1,3002-1,3096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/standard_224/1,2-1,96_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/standard_224/1,2-1,96_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/standard_224/1,1002-1,1096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/standard_224/1,1002-1,1096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/standard_224/1,2002-1,2096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/standard_224/1,2002-1,2096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/standard_160/1,3002-1,3096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/standard_160/1,3002-1,3096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/standard_160/1,2-1,96_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/standard_160/1,2-1,96_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/standard_160/1,1002-1,1096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/standard_160/1,1002-1,1096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/standard_160/1,2002-1,2096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/standard_160/1,2002-1,2096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/across_224/1,3002-1,3096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/across_224/1,3002-1,3096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/across_224/1,2-1,96_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/across_224/1,2-1,96_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/across_224/1,1002-1,1096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/across_224/1,1002-1,1096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/across_224/1,2002-1,2096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/across_224/1,2002-1,2096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/across_160/1,3002-1,3096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/across_160/1,3002-1,3096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/across_160/1,2-1,96_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/across_160/1,2-1,96_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/across_160/1,1002-1,1096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/across_160/1,1002-1,1096_aligned.jls\n",
      "Loading data from /home/ubuntu/davit/across_160/1,2002-1,2096_aligned.jls\n",
      "Loaded MeshSet from /home/ubuntu/davit/across_160/1,2002-1,2096_aligned.jls\n"
     ]
    }
   ],
   "source": [
    "exp_dirs = [\"standard_224\", \"standard_160\", \"across_224\", \"across_160\"]\n",
    "ms_filenames = Dict(\n",
    "    \"original\" => \"1,2-1,96_aligned.jls\",\n",
    "    \"net_adj\" => \"1,1002-1,1096_aligned.jls\",\n",
    "    \"net_across\" => \"1,2002-1,2096_aligned.jls\",\n",
    "    \"bandpass\" => \"1,3002-1,3096_aligned.jls\")\n",
    "\n",
    "exp_dict = Dict()\n",
    "for exp_dir in exp_dirs\n",
    "    ms_dir = joinpath(homedir(), \"davit\", exp_dir)\n",
    "    exp_dict[exp_dir] = [k => load(joinpath(ms_dir, v)) for (k,v) in ms_filenames]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ms_names = collect(keys(ms_filenames))\n",
    "comparisons = [(\"original\", \"net_adj\"),\n",
    "                (\"original\", \"net_across\"),\n",
    "                (\"original\", \"bandpass\"),\n",
    "                (\"net_adj\", \"net_across\"),\n",
    "                (\"net_adj\", \"bandpass\"),\n",
    "                (\"net_across\", \"bandpass\")];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare meshsets  \n",
    "A good kernel should create _more good matches_ and make it _easier to remove bad matches_.  \n",
    "\n",
    "_More good matches_ means:  \n",
    "1. a kernel finds good correspondences in locations where another kernel might not be able to find any.  \n",
    "1. there is better coverage of matches (a more consistent density).   \n",
    "\n",
    "_Easier to remove bad matches_ means:   \n",
    "1. there are fewer bad matches overall.\n",
    "1. we can filter out bad matches with an easily tuned filter (less need for manual intervention).  \n",
    "\n",
    "To start evaluating these two criteria, we will inspect the f-score between pairs of kernels, as well as number of matches away from a perfect set of correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_f1 (generic function with 2 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Count TP, FP, FN between matchA & matchB (ground truth: matchA)\n",
    "\"\"\"\n",
    "function compare_matches(matchA, matchB)\n",
    "    pA = Set(get_filtered_properties(matchA, \"src_range\"));\n",
    "    pB = Set(get_filtered_properties(matchB, \"src_range\"));\n",
    "    tp = length(intersect(pA, pB))\n",
    "    fn = length(setdiff(pA, pB))\n",
    "    fp = length(setdiff(pB, pA))\n",
    "    return [tp, fn, fp]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Compute F1-score\n",
    "\"\"\"\n",
    "function compute_f1(tp, fn, fp)\n",
    "    return 2*tp / (2*tp + fn + fp)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Compute F1-score from table of tp, fn, fp\n",
    "\"\"\"\n",
    "function compute_f1(pn)\n",
    "    f1_array = zeros(size(pn,1))\n",
    "    for i in 1:size(pn,1)\n",
    "        f1_array[i] = compute_f1(pn[i,:]...)\n",
    "    end\n",
    "    f1 = compute_f1(sum(pn,1)[:]...)\n",
    "    return f1, f1_array\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compare_meshsets (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Count TP, FP, FN between all corresponding matches (ground truth: msA)\n",
    "\"\"\"\n",
    "function compare_meshsets(msA, msB)\n",
    "    pn = zeros(Int64, length(msA.matches), 3)\n",
    "    for (k, (matchA, matchB)) in enumerate(zip(msA.matches, msB.matches))\n",
    "        pn[k,:] = [compare_matches(matchA, matchB)...]\n",
    "    end\n",
    "    return pn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_errors (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function count_errors(ms, match)\n",
    "    src_index = match.src_index\n",
    "    mesh = get_mesh(ms, match.src_index)\n",
    "    attempted_matches = length(mesh.src_nodes)\n",
    "    possible_matches = length(get_properties(match, \"src_range\"))\n",
    "    good_matches = length(get_filtered_properties(match, \"src_range\"))\n",
    "    return [attempted_matches, possible_matches, good_matches]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list_discrepancies (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function list_discrepancies(matchA, matchB)\n",
    "    pA = Set(get_filtered_properties(matchA, \"src_range\"));\n",
    "    pB = Set(get_filtered_properties(matchB, \"src_range\"));\n",
    "    fn = setdiff(pA, pB)\n",
    "    fp = setdiff(pB, pA)\n",
    "    return fn, fp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compile_pn (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compile_pn(ms_dict, comparisons)\n",
    "    pn_results = Dict()\n",
    "    for (nameA, nameB) in comparisons\n",
    "        pn = compare_meshsets(ms_dict[nameA], ms_dict[nameB])\n",
    "        pn_results[(nameA, nameB)] = pn\n",
    "    end\n",
    "    return pn_results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compile_f1 (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compile_f1(pn_results)\n",
    "    f1_results = Dict()\n",
    "    for (name_pair, pn) in pn_results\n",
    "        f1_results[name_pair] = compute_f1(pn)\n",
    "    end\n",
    "    return f1_results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_pn = Dict()\n",
    "for (exp, ms_dict) in exp_dict\n",
    "    exp_pn[exp] = compile_pn(ms_dict, comparisons)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_f1 = Dict()\n",
    "for (exp, pn_results) in exp_pn\n",
    "    exp_f1[exp] = compile_f1(pn_results)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compile_tables (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compile_tables(pn_results, f1_results)\n",
    "    pn_table = zeros(Int64, length(ms_names), length(ms_names), 3)\n",
    "    f1_table = zeros(length(ms_names), length(ms_names))\n",
    "    for (i, nameA) in enumerate(ms_names)\n",
    "        for (j, nameB) in enumerate(ms_names)\n",
    "            if (nameA, nameB) in keys(f1_results)\n",
    "                pn_table[i,j,:] = sum(pn_results[(nameA, nameB)],1)\n",
    "                f1_table[i,j] = f1_results[(nameA, nameB)][1]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return pn_table, f1_table\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_tables = Dict()\n",
    "for exp_name in keys(exp_pn)\n",
    "    pn_results = exp_pn[exp_name]\n",
    "    f1_results = exp_f1[exp_name]\n",
    "    exp_tables[exp_name] = compile_tables(pn_results, f1_results)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCIIString[\"original\",\"net_adj\",\"bandpass\"]\n",
      "\n",
      "across_160\n",
      "tp\n",
      "[0 70178 69528\n",
      " 0 0 70749\n",
      " 0 0 0]\n",
      "fn\n",
      "[0 59 709\n",
      " 0 0 1333\n",
      " 0 0 0]\n",
      "fp\n",
      "[0 1904 1287\n",
      " 0 0 66\n",
      " 0 0 0]\n",
      "f1\n",
      "[0.0 0.9862 0.9858\n",
      " 0.0 0.0 0.9902\n",
      " 0.0 0.0 0.0]\n",
      "across_224\n",
      "tp\n",
      "[0 71247 71170\n",
      " 0 0 71972\n",
      " 0 0 0]\n",
      "fn\n",
      "[0 6 83\n",
      " 0 0 289\n",
      " 0 0 0]\n",
      "fp\n",
      "[0 1014 814\n",
      " 0 0 12\n",
      " 0 0 0]\n",
      "f1\n",
      "[0.0 0.9929 0.9937\n",
      " 0.0 0.0 0.9979\n",
      " 0.0 0.0 0.0]\n",
      "standard_160\n",
      "tp\n",
      "[0 142680 142681\n",
      " 0 0 143954\n",
      " 0 0 0]\n",
      "fn\n",
      "[0 76 75\n",
      " 0 0 287\n",
      " 0 0 0]\n",
      "fp\n",
      "[0 1561 1396\n",
      " 0 0 123\n",
      " 0 0 0]\n",
      "f1\n",
      "[0.0 0.9943 0.9949\n",
      " 0.0 0.0 0.9986\n",
      " 0.0 0.0 0.0]\n",
      "standard_224\n",
      "tp\n",
      "[0 143672 143657\n",
      " 0 0 144342\n",
      " 0 0 0]\n",
      "fn\n",
      "[0 12 27\n",
      " 0 0 94\n",
      " 0 0 0]\n",
      "fp\n",
      "[0 764 702\n",
      " 0 0 17\n",
      " 0 0 0]\n",
      "f1\n",
      "[0.0 0.9973 0.9975\n",
      " 0.0 0.0 0.9996\n",
      " 0.0 0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "s = collect([2,3,1])\n",
    "println(ms_names[s])\n",
    "println()\n",
    "for (exp_name, (pn_table, f1_table)) in exp_tables\n",
    "    println(exp_name)\n",
    "    for (k, t) in enumerate([\"tp\", \"fn\", \"fp\"])\n",
    "        println(t)\n",
    "        println(pn_table[s,s,k])\n",
    "    end\n",
    "    println(\"f1\")\n",
    "    println(round(f1_table[s,s], 4))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compile_errors (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compile_errors(ms_dict)\n",
    "    error_results = Dict()\n",
    "    for (name, ms) in ms_dict\n",
    "        error_results[name] = zeros(Int64, 3)\n",
    "        for match in ms.matches\n",
    "            error_results[name] += count_errors(ms, match)\n",
    "        end\n",
    "    end\n",
    "    return error_results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_error = Dict()\n",
    "for (exp_name, ms_dict) in exp_dict\n",
    "    exp_error[exp_name] = compile_errors(ms_dict)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across_160\n",
      "bandpass [85399,72306,70815]\n",
      "original [85399,72306,70237]\n",
      "net_adj [85399,72347,72082]\n",
      "net_across [81765,69251,68971]\n",
      "\n",
      "across_224\n",
      "bandpass [85399,72306,71984]\n",
      "original [85399,72306,71253]\n",
      "net_adj [85399,72347,72261]\n",
      "net_across [81765,69251,69151]\n",
      "\n",
      "standard_160\n",
      "bandpass [170798,144500,144077]\n",
      "original [170798,144500,142756]\n",
      "net_adj [170798,144539,144241]\n",
      "net_across [163530,138283,137809]\n",
      "\n",
      "standard_224\n",
      "bandpass [170798,144500,144359]\n",
      "original [170798,144500,143684]\n",
      "net_adj [170798,144539,144436]\n",
      "net_across [163530,138302,138105]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (exp_name, error_results) in exp_error\n",
    "    println(exp_name)\n",
    "    for (ms_name, error_array) in error_results\n",
    "        println(\"$ms_name $error_array\")\n",
    "    end\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across_160\n",
      "bandpass \t 1491\n",
      "original \t 2069\n",
      "net_adj \t 224\n",
      "net_across \t 280\n",
      "\n",
      "across_224\n",
      "bandpass \t 322\n",
      "original \t 1053\n",
      "net_adj \t 45\n",
      "net_across \t 100\n",
      "\n",
      "standard_160\n",
      "bandpass \t 423\n",
      "original \t 1744\n",
      "net_adj \t 259\n",
      "net_across \t 474\n",
      "\n",
      "standard_224\n",
      "bandpass \t 141\n",
      "original \t 816\n",
      "net_adj \t 64\n",
      "net_across \t 197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (exp_name, error_results) in exp_error\n",
    "    println(exp_name)\n",
    "    d = 144500 # hardcode at 144500, because the net kernel created areas that it could match\n",
    "    if exp_name[1:6] == \"across\"\n",
    "        d = 72306\n",
    "    end\n",
    "    for (ms_name, error_array) in error_results\n",
    "        if ms_name == \"net_across\"\n",
    "                println(\"$ms_name \\t $(error_array[2] - error_array[3])\")\n",
    "        else\n",
    "            println(\"$ms_name \\t $(d - error_array[3])\")\n",
    "        end\n",
    "    end\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PR curves   \n",
    "Let's explore how robustly we can filter the matches generated by different kernels. This is a test of how easy we can remove matches.  \n",
    "\n",
    "We'll vary parameters for the following filters:  \n",
    "* distance  \n",
    "* r delta\n",
    "* r-max\n",
    "* sigma (0.75?)  \n",
    "\n",
    "We'll plot precision and recall curves for each filter as we vary the one parameter of the filter. We'll be comparing it to the ground truth we've created.  \n",
    "\n",
    "We're writing out the important params as CSV files, because these Alembic gcloud instances don't plot easily.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compile_params (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compile_params(ms, name)\n",
    "    total_correspondences = count_correspondences(ms)\n",
    "    compiled_params = zeros(total_correspondences,5)\n",
    "    n = 1\n",
    "    for match in ms.matches\n",
    "        m = count_correspondences(match)\n",
    "        filtered = ones(m)\n",
    "        filtered[collect(get_rejected_indices(match))] = 0\n",
    "        dist = get_properties(match, \"norm\")\n",
    "        r_max = get_properties(match, \"r_max\")\n",
    "        sigma = get_properties(match, 0.75)\n",
    "        r_delta = get_properties(match, 10)\n",
    "        params = hcat(filtered, dist, r_max, sigma, r_delta)\n",
    "        compiled_params[n:n+m-1,:] = params\n",
    "        n += m\n",
    "    end\n",
    "    writedlm(joinpath(homedir(), \"davit\", string(name, \"_params.csv\")), compiled_params) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compile_params(exp_dict[\"standard_224\"][\"net_adj\"], \"standard_224_net_adj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (exp_name, ms_dict) in exp_dict\n",
    "    for (ms_name, ms) in ms_dict\n",
    "        fn = join([exp_name, ms_name], \"_\")\n",
    "        compile_params(ms, fn)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.6",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
